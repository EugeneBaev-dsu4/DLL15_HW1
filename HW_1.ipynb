{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ed8961",
   "metadata": {},
   "source": [
    "### Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6a99e",
   "metadata": {},
   "source": [
    "1. Реализовать обучение линейной регрессии для задачи boston house prices (https://www.kaggle.com/vikrishnan/boston-house-prices) с использованием torch’а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e97d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a11d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62caa312",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = boston['data']\n",
    "target = boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5e24301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f5b6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tensor\n",
    "data  = torch.tensor(data).float()[:-10]\n",
    "target = torch.tensor(target).float()[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34fc9eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BEU_RU1\\AppData\\Local\\Temp/ipykernel_3392/3826391005.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val = torch.tensor(data).float()[-10:]\n",
      "C:\\Users\\BEU_RU1\\AppData\\Local\\Temp/ipykernel_3392/3826391005.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val = torch.tensor(target).float()[-10:]\n"
     ]
    }
   ],
   "source": [
    "X_val = torch.tensor(data).float()[-10:]\n",
    "y_val = torch.tensor(target).float()[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a2b4b0",
   "metadata": {},
   "source": [
    "#### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae776038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.7440e-02, 0.0000e+00, 5.9600e+00, 0.0000e+00, 4.9900e-01, 5.8410e+00,\n",
      "         6.1400e+01, 3.3779e+00, 5.0000e+00, 2.7900e+02, 1.9200e+01, 3.7756e+02,\n",
      "         1.1410e+01],\n",
      "        [2.9850e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01, 6.4300e+00,\n",
      "         5.8700e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02, 1.8700e+01, 3.9412e+02,\n",
      "         5.2100e+00],\n",
      "        [3.6782e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 7.7000e-01, 5.3620e+00,\n",
      "         9.6200e+01, 2.1036e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.8079e+02,\n",
      "         1.0190e+01],\n",
      "        [5.3720e-02, 0.0000e+00, 1.3920e+01, 0.0000e+00, 4.3700e-01, 6.5490e+00,\n",
      "         5.1000e+01, 5.9604e+00, 4.0000e+00, 2.8900e+02, 1.6000e+01, 3.9285e+02,\n",
      "         7.3900e+00],\n",
      "        [3.3147e-01, 0.0000e+00, 6.2000e+00, 0.0000e+00, 5.0700e-01, 8.2470e+00,\n",
      "         7.0400e+01, 3.6519e+00, 8.0000e+00, 3.0700e+02, 1.7400e+01, 3.7895e+02,\n",
      "         3.9500e+00],\n",
      "        [2.8392e-01, 0.0000e+00, 7.3800e+00, 0.0000e+00, 4.9300e-01, 5.7080e+00,\n",
      "         7.4300e+01, 4.7211e+00, 5.0000e+00, 2.8700e+02, 1.9600e+01, 3.9113e+02,\n",
      "         1.1740e+01],\n",
      "        [2.0716e+01, 0.0000e+00, 1.8100e+01, 0.0000e+00, 6.5900e-01, 4.1380e+00,\n",
      "         1.0000e+02, 1.1781e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.7022e+02,\n",
      "         2.3340e+01],\n",
      "        [6.6351e-01, 2.0000e+01, 3.9700e+00, 0.0000e+00, 6.4700e-01, 7.3330e+00,\n",
      "         1.0000e+02, 1.8946e+00, 5.0000e+00, 2.6400e+02, 1.3000e+01, 3.8329e+02,\n",
      "         7.7900e+00],\n",
      "        [1.2757e-01, 3.0000e+01, 4.9300e+00, 0.0000e+00, 4.2800e-01, 6.3930e+00,\n",
      "         7.8000e+00, 7.0355e+00, 6.0000e+00, 3.0000e+02, 1.6600e+01, 3.7471e+02,\n",
      "         5.1900e+00],\n",
      "        [2.5199e-01, 0.0000e+00, 1.0590e+01, 0.0000e+00, 4.8900e-01, 5.7830e+00,\n",
      "         7.2700e+01, 4.3549e+00, 4.0000e+00, 2.7700e+02, 1.8600e+01, 3.8943e+02,\n",
      "         1.8060e+01]]) tensor([20.0000, 28.7000, 20.8000, 27.1000, 48.3000, 18.5000, 11.9000, 36.0000,\n",
      "        23.7000, 22.5000])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "dataset = TensorDataset(data, target)\n",
    "\n",
    "# Randomly reading mini-batches\n",
    "data_iter = DataLoader(dataset, batch_size, shuffle=True)\n",
    "\n",
    "# Read a batch to see how it works\n",
    "for X, y in data_iter:\n",
    "    print(X,y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b67a3",
   "metadata": {},
   "source": [
    "#### Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1c364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(13,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aa4e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.modules():\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.normal(m.weight, mean=0, std=0.01)\n",
    "        torch.nn.init.constant(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b920cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1965, -0.1939, -0.0618,  0.2262, -0.1391, -0.2367, -0.2540, -0.1979,\n",
       "         -0.2470,  0.2701,  0.2229, -0.2468,  0.0509]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.data.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "302c697f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1369], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].bias.data.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab24b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d537acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4187f72c",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f3f4c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 3304.497559\n",
      "w tensor([[ 0.1644, -0.1579, -0.0800,  0.2412, -0.1242, -0.2051, -0.2475, -0.1562,\n",
      "         -0.2787,  0.2565,  0.2464, -0.2069,  0.0416]])\n",
      "b tensor([-0.1082])\n",
      "epoch 2, loss 2566.875977\n",
      "w tensor([[ 0.1309, -0.1255, -0.1054,  0.2605, -0.1186, -0.1815, -0.2480, -0.1218,\n",
      "         -0.3160,  0.2342,  0.2607, -0.1745,  0.0234]])\n",
      "b tensor([-0.0880])\n",
      "epoch 3, loss 1955.856201\n",
      "w tensor([[ 0.0992, -0.0942, -0.1309,  0.2770, -0.1168, -0.1616, -0.2518, -0.0900,\n",
      "         -0.3502,  0.2110,  0.2713, -0.1452,  0.0051]])\n",
      "b tensor([-0.0715])\n",
      "epoch 4, loss 1466.477661\n",
      "w tensor([[ 0.0710, -0.0655, -0.1531,  0.2917, -0.1133, -0.1414, -0.2525, -0.0601,\n",
      "         -0.3810,  0.1904,  0.2826, -0.1170, -0.0127]])\n",
      "b tensor([-0.0544])\n",
      "epoch 5, loss 1083.588257\n",
      "w tensor([[ 0.0457, -0.0403, -0.1732,  0.3083, -0.1099, -0.1225, -0.2532, -0.0332,\n",
      "         -0.4101,  0.1709,  0.2928, -0.0912, -0.0277]])\n",
      "b tensor([-0.0388])\n",
      "epoch 6, loss 794.568420\n",
      "w tensor([[ 0.0225, -0.0184, -0.1926,  0.3218, -0.1080, -0.1066, -0.2539, -0.0103,\n",
      "         -0.4364,  0.1521,  0.3003, -0.0692, -0.0427]])\n",
      "b tensor([-0.0259])\n",
      "epoch 7, loss 577.973267\n",
      "w tensor([[ 0.0010,  0.0006, -0.2077,  0.3389, -0.1041, -0.0906, -0.2511,  0.0101,\n",
      "         -0.4592,  0.1363,  0.3084, -0.0482, -0.0551]])\n",
      "b tensor([-0.0129])\n",
      "epoch 8, loss 424.552124\n",
      "w tensor([[-0.0172,  0.0160, -0.2214,  0.3545, -0.1018, -0.0774, -0.2492,  0.0265,\n",
      "         -0.4795,  0.1216,  0.3143, -0.0308, -0.0670]])\n",
      "b tensor([-0.0026])\n",
      "epoch 9, loss 320.118195\n",
      "w tensor([[-0.0321,  0.0271, -0.2315,  0.3680, -0.0977, -0.0647, -0.2446,  0.0404,\n",
      "         -0.4955,  0.1103,  0.3209, -0.0152, -0.0753]])\n",
      "b tensor([0.0078])\n",
      "epoch 10, loss 246.115204\n",
      "w tensor([[-0.0453,  0.0360, -0.2411,  0.3829, -0.0949, -0.0540, -0.2403,  0.0506,\n",
      "         -0.5105,  0.0989,  0.3250, -0.0030, -0.0848]])\n",
      "b tensor([0.0157])\n",
      "epoch 11, loss 196.683105\n",
      "w tensor([[-0.0563,  0.0424, -0.2476,  0.3969, -0.0908, -0.0437, -0.2339,  0.0587,\n",
      "         -0.5225,  0.0901,  0.3295,  0.0079, -0.0917]])\n",
      "b tensor([0.0236])\n",
      "epoch 12, loss 164.563004\n",
      "w tensor([[-0.0654,  0.0464, -0.2527,  0.4110, -0.0876, -0.0353, -0.2281,  0.0639,\n",
      "         -0.5322,  0.0822,  0.3326,  0.0160, -0.0983]])\n",
      "b tensor([0.0297])\n",
      "epoch 13, loss 142.670135\n",
      "w tensor([[-0.0736,  0.0479, -0.2573,  0.4228, -0.0842, -0.0274, -0.2210,  0.0667,\n",
      "         -0.5410,  0.0749,  0.3348,  0.0225, -0.1049]])\n",
      "b tensor([0.0350])\n",
      "epoch 14, loss 127.845062\n",
      "w tensor([[-0.0792,  0.0484, -0.2580,  0.4369, -0.0788, -0.0190, -0.2120,  0.0686,\n",
      "         -0.5465,  0.0705,  0.3383,  0.0288, -0.1085]])\n",
      "b tensor([0.0413])\n",
      "epoch 15, loss 118.088882\n",
      "w tensor([[-0.0842,  0.0475, -0.2608,  0.4495, -0.0758, -0.0128, -0.2050,  0.0680,\n",
      "         -0.5520,  0.0648,  0.3392,  0.0322, -0.1141]])\n",
      "b tensor([0.0449])\n",
      "epoch 16, loss 111.157097\n",
      "w tensor([[-0.0873,  0.0462, -0.2601,  0.4624, -0.0700, -0.0047, -0.1952,  0.0681,\n",
      "         -0.5548,  0.0626,  0.3427,  0.0367, -0.1169]])\n",
      "b tensor([0.0507])\n",
      "epoch 17, loss 105.173630\n",
      "w tensor([[-0.0903,  0.0432, -0.2608,  0.4749, -0.0665,  0.0008, -0.1870,  0.0650,\n",
      "         -0.5579,  0.0585,  0.3433,  0.0385, -0.1216]])\n",
      "b tensor([0.0537])\n",
      "epoch 18, loss 101.109077\n",
      "w tensor([[-0.0928,  0.0415, -0.2604,  0.4875, -0.0619,  0.0072, -0.1784,  0.0632,\n",
      "         -0.5597,  0.0560,  0.3450,  0.0405, -0.1250]])\n",
      "b tensor([0.0578])\n",
      "epoch 19, loss 97.779640\n",
      "w tensor([[-0.0946,  0.0384, -0.2605,  0.5006, -0.0583,  0.0126, -0.1705,  0.0596,\n",
      "         -0.5613,  0.0529,  0.3452,  0.0412, -0.1299]])\n",
      "b tensor([0.0606])\n",
      "epoch 20, loss 94.512833\n",
      "w tensor([[-0.0950,  0.0354, -0.2594,  0.5149, -0.0535,  0.0189, -0.1610,  0.0561,\n",
      "         -0.5617,  0.0511,  0.3466,  0.0424, -0.1334]])\n",
      "b tensor([0.0643])\n",
      "epoch 21, loss 92.040901\n",
      "w tensor([[-0.0964,  0.0338, -0.2585,  0.5266, -0.0492,  0.0249, -0.1529,  0.0530,\n",
      "         -0.5616,  0.0494,  0.3475,  0.0429, -0.1376]])\n",
      "b tensor([0.0677])\n",
      "epoch 22, loss 89.537834\n",
      "w tensor([[-0.0966,  0.0308, -0.2566,  0.5391, -0.0441,  0.0313, -0.1434,  0.0494,\n",
      "         -0.5616,  0.0482,  0.3490,  0.0436, -0.1409]])\n",
      "b tensor([0.0716])\n",
      "epoch 23, loss 87.310753\n",
      "w tensor([[-0.0966,  0.0284, -0.2551,  0.5535, -0.0399,  0.0369, -0.1348,  0.0438,\n",
      "         -0.5606,  0.0469,  0.3491,  0.0431, -0.1456]])\n",
      "b tensor([0.0742])\n",
      "epoch 24, loss 85.730423\n",
      "w tensor([[-0.0967,  0.0272, -0.2535,  0.5658, -0.0346,  0.0438, -0.1262,  0.0415,\n",
      "         -0.5600,  0.0460,  0.3511,  0.0439, -0.1490]])\n",
      "b tensor([0.0786])\n",
      "epoch 25, loss 85.081352\n",
      "w tensor([[-0.0979,  0.0275, -0.2554,  0.5803, -0.0327,  0.0483, -0.1207,  0.0367,\n",
      "         -0.5602,  0.0425,  0.3492,  0.0423, -0.1569]])\n",
      "b tensor([0.0798])\n",
      "epoch 26, loss 81.818985\n",
      "w tensor([[-0.0966,  0.0253, -0.2524,  0.5928, -0.0260,  0.0567, -0.1103,  0.0331,\n",
      "         -0.5576,  0.0432,  0.3519,  0.0437, -0.1606]])\n",
      "b tensor([0.0850])\n",
      "epoch 27, loss 81.237038\n",
      "w tensor([[-0.0967,  0.0240, -0.2518,  0.6061, -0.0235,  0.0611, -0.1042,  0.0274,\n",
      "         -0.5572,  0.0410,  0.3504,  0.0414, -0.1677]])\n",
      "b tensor([0.0864])\n",
      "epoch 28, loss 78.650955\n",
      "w tensor([[-0.0969,  0.0240, -0.2501,  0.6192, -0.0175,  0.0694, -0.0956,  0.0249,\n",
      "         -0.5551,  0.0410,  0.3527,  0.0427, -0.1724]])\n",
      "b tensor([0.0914])\n",
      "epoch 29, loss 77.415291\n",
      "w tensor([[-0.0959,  0.0251, -0.2497,  0.6339, -0.0123,  0.0770, -0.0878,  0.0224,\n",
      "         -0.5536,  0.0402,  0.3540,  0.0431, -0.1774]])\n",
      "b tensor([0.0958])\n",
      "epoch 30, loss 76.084068\n",
      "w tensor([[-0.0959,  0.0257, -0.2486,  0.6470, -0.0080,  0.0837, -0.0807,  0.0185,\n",
      "         -0.5516,  0.0394,  0.3546,  0.0426, -0.1840]])\n",
      "b tensor([0.0991])\n",
      "epoch 31, loss 76.677727\n",
      "w tensor([[-0.0952,  0.0262, -0.2476,  0.6579, -0.0023,  0.0919, -0.0728,  0.0155,\n",
      "         -0.5482,  0.0398,  0.3566,  0.0431, -0.1899]])\n",
      "b tensor([0.1039])\n",
      "epoch 32, loss 73.588661\n",
      "w tensor([[-9.4823e-02,  2.6683e-02, -2.4804e-01,  6.7203e-01,  4.1792e-04,\n",
      "          9.7627e-02, -6.7680e-02,  1.0815e-02, -5.4688e-01,  3.7953e-02,\n",
      "          3.5559e-01,  4.1459e-02, -1.9781e-01]])\n",
      "b tensor([0.1060])\n",
      "epoch 33, loss 73.018196\n",
      "w tensor([[-0.0944,  0.0268, -0.2474,  0.6861,  0.0058,  0.1055, -0.0606,  0.0080,\n",
      "         -0.5441,  0.0378,  0.3571,  0.0415, -0.2041]])\n",
      "b tensor([0.1105])\n",
      "epoch 34, loss 72.700714\n",
      "w tensor([[-0.0951,  0.0278, -0.2491,  0.7003,  0.0076,  0.1108, -0.0566,  0.0027,\n",
      "         -0.5437,  0.0347,  0.3551,  0.0393, -0.2138]])\n",
      "b tensor([0.1119])\n",
      "epoch 35, loss 70.888855\n",
      "w tensor([[-9.3674e-02,  3.0771e-02, -2.4851e-01,  7.1364e-01,  1.2208e-02,\n",
      "          1.1863e-01, -5.0806e-02,  6.3028e-04, -5.4056e-01,  3.4892e-02,\n",
      "          3.5645e-01,  3.9042e-02, -2.2081e-01]])\n",
      "b tensor([0.1162])\n",
      "epoch 36, loss 69.805664\n",
      "w tensor([[-0.0936,  0.0325, -0.2464,  0.7277,  0.0188,  0.1284, -0.0427, -0.0012,\n",
      "         -0.5376,  0.0354,  0.3591,  0.0406, -0.2268]])\n",
      "b tensor([0.1221])\n",
      "epoch 37, loss 68.716637\n",
      "w tensor([[-0.0927,  0.0349, -0.2485,  0.7416,  0.0215,  0.1348, -0.0386, -0.0047,\n",
      "         -0.5352,  0.0334,  0.3580,  0.0387, -0.2367]])\n",
      "b tensor([0.1245])\n",
      "epoch 38, loss 68.140335\n",
      "w tensor([[-0.0925,  0.0360, -0.2481,  0.7547,  0.0256,  0.1422, -0.0337, -0.0084,\n",
      "         -0.5328,  0.0327,  0.3584,  0.0381, -0.2452]])\n",
      "b tensor([0.1282])\n",
      "epoch 39, loss 66.602272\n",
      "w tensor([[-0.0911,  0.0391, -0.2471,  0.7707,  0.0309,  0.1508, -0.0273, -0.0115,\n",
      "         -0.5289,  0.0330,  0.3597,  0.0383, -0.2525]])\n",
      "b tensor([0.1328])\n",
      "epoch 40, loss 65.829620\n",
      "w tensor([[-0.0912,  0.0412, -0.2479,  0.7829,  0.0352,  0.1587, -0.0226, -0.0140,\n",
      "         -0.5260,  0.0322,  0.3604,  0.0380, -0.2613]])\n",
      "b tensor([0.1369])\n",
      "epoch 41, loss 65.823883\n",
      "w tensor([[-0.0908,  0.0431, -0.2484,  0.8015,  0.0390,  0.1665, -0.0177, -0.0178,\n",
      "         -0.5239,  0.0307,  0.3601,  0.0369, -0.2707]])\n",
      "b tensor([0.1404])\n",
      "epoch 42, loss 66.838249\n",
      "w tensor([[-0.0891,  0.0468, -0.2461,  0.8151,  0.0465,  0.1772, -0.0108, -0.0178,\n",
      "         -0.5188,  0.0329,  0.3640,  0.0396, -0.2762]])\n",
      "b tensor([0.1476])\n",
      "epoch 43, loss 63.490746\n",
      "w tensor([[-0.0887,  0.0460, -0.2465,  0.8301,  0.0491,  0.1836, -0.0077, -0.0234,\n",
      "         -0.5157,  0.0313,  0.3626,  0.0370, -0.2872]])\n",
      "b tensor([0.1497])\n",
      "epoch 44, loss 62.779453\n",
      "w tensor([[-0.0880,  0.0507, -0.2465,  0.8442,  0.0536,  0.1924, -0.0037, -0.0247,\n",
      "         -0.5128,  0.0308,  0.3636,  0.0367, -0.2960]])\n",
      "b tensor([0.1543])\n",
      "epoch 45, loss 62.041454\n",
      "w tensor([[-8.8197e-02,  5.2627e-02, -2.4758e-01,  8.5755e-01,  5.7794e-02,\n",
      "          2.0099e-01,  7.5009e-04, -2.8759e-02, -5.0958e-01,  2.9768e-02,\n",
      "          3.6380e-01,  3.6541e-02, -3.0645e-01]])\n",
      "b tensor([0.1584])\n",
      "epoch 46, loss 61.866108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w tensor([[-0.0861,  0.0552, -0.2467,  0.8724,  0.0634,  0.2100,  0.0057, -0.0309,\n",
      "         -0.5045,  0.0306,  0.3657,  0.0366, -0.3140]])\n",
      "b tensor([0.1636])\n",
      "epoch 47, loss 60.978855\n",
      "w tensor([[-0.0860,  0.0573, -0.2466,  0.8844,  0.0676,  0.2183,  0.0094, -0.0338,\n",
      "         -0.5013,  0.0300,  0.3662,  0.0361, -0.3237]])\n",
      "b tensor([0.1679])\n",
      "epoch 48, loss 60.903126\n",
      "w tensor([[-0.0848,  0.0596, -0.2469,  0.8997,  0.0725,  0.2277,  0.0132, -0.0352,\n",
      "         -0.4971,  0.0299,  0.3679,  0.0363, -0.3323]])\n",
      "b tensor([0.1731])\n",
      "epoch 49, loss 59.652054\n",
      "w tensor([[-0.0845,  0.0612, -0.2477,  0.9134,  0.0765,  0.2363,  0.0167, -0.0393,\n",
      "         -0.4937,  0.0289,  0.3677,  0.0358, -0.3441]])\n",
      "b tensor([0.1771])\n",
      "epoch 50, loss 60.725712\n",
      "w tensor([[-0.0833,  0.0626, -0.2463,  0.9277,  0.0821,  0.2455,  0.0216, -0.0413,\n",
      "         -0.4886,  0.0300,  0.3698,  0.0359, -0.3514]])\n",
      "b tensor([0.1825])\n",
      "epoch 51, loss 58.364376\n",
      "w tensor([[-0.0843,  0.0637, -0.2477,  0.9423,  0.0852,  0.2535,  0.0232, -0.0457,\n",
      "         -0.4859,  0.0278,  0.3691,  0.0344, -0.3630]])\n",
      "b tensor([0.1858])\n",
      "epoch 52, loss 57.826664\n",
      "w tensor([[-0.0836,  0.0665, -0.2472,  0.9536,  0.0897,  0.2622,  0.0266, -0.0479,\n",
      "         -0.4817,  0.0277,  0.3699,  0.0339, -0.3718]])\n",
      "b tensor([0.1904])\n",
      "epoch 53, loss 57.798237\n",
      "w tensor([[-0.0834,  0.0656, -0.2472,  0.9701,  0.0934,  0.2701,  0.0293, -0.0527,\n",
      "         -0.4783,  0.0267,  0.3696,  0.0329, -0.3820]])\n",
      "b tensor([0.1940])\n",
      "epoch 54, loss 56.768501\n",
      "w tensor([[-0.0819,  0.0674, -0.2472,  0.9836,  0.0990,  0.2803,  0.0334, -0.0548,\n",
      "         -0.4726,  0.0270,  0.3714,  0.0333, -0.3913]])\n",
      "b tensor([0.1997])\n",
      "epoch 55, loss 56.652641\n",
      "w tensor([[-0.0807,  0.0690, -0.2461,  1.0006,  0.1041,  0.2897,  0.0368, -0.0574,\n",
      "         -0.4675,  0.0276,  0.3730,  0.0338, -0.4006]])\n",
      "b tensor([0.2051])\n",
      "epoch 56, loss 55.777863\n",
      "w tensor([[-0.0816,  0.0704, -0.2467,  1.0133,  0.1084,  0.2990,  0.0390, -0.0605,\n",
      "         -0.4645,  0.0264,  0.3733,  0.0333, -0.4114]])\n",
      "b tensor([0.2096])\n",
      "epoch 57, loss 55.405750\n",
      "w tensor([[-0.0794,  0.0724, -0.2461,  1.0263,  0.1139,  0.3083,  0.0426, -0.0635,\n",
      "         -0.4590,  0.0266,  0.3746,  0.0329, -0.4195]])\n",
      "b tensor([0.2149])\n",
      "epoch 58, loss 54.918560\n",
      "w tensor([[-0.0792,  0.0726, -0.2463,  1.0410,  0.1186,  0.3178,  0.0453, -0.0662,\n",
      "         -0.4543,  0.0262,  0.3756,  0.0329, -0.4299]])\n",
      "b tensor([0.2198])\n",
      "epoch 59, loss 57.545162\n",
      "w tensor([[-0.0780,  0.0759, -0.2451,  1.0566,  0.1250,  0.3286,  0.0485, -0.0666,\n",
      "         -0.4482,  0.0279,  0.3786,  0.0338, -0.4366]])\n",
      "b tensor([0.2267])\n",
      "epoch 60, loss 53.988865\n",
      "w tensor([[-0.0780,  0.0743, -0.2461,  1.0713,  0.1281,  0.3368,  0.0499, -0.0719,\n",
      "         -0.4455,  0.0254,  0.3774,  0.0323, -0.4483]])\n",
      "b tensor([0.2300])\n",
      "epoch 61, loss 53.626617\n",
      "w tensor([[-0.0771,  0.0764, -0.2465,  1.0844,  0.1326,  0.3463,  0.0517, -0.0741,\n",
      "         -0.4410,  0.0246,  0.3784,  0.0318, -0.4568]])\n",
      "b tensor([0.2351])\n",
      "epoch 62, loss 53.270863\n",
      "w tensor([[-0.0767,  0.0774, -0.2452,  1.0996,  0.1382,  0.3564,  0.0546, -0.0770,\n",
      "         -0.4363,  0.0248,  0.3799,  0.0325, -0.4662]])\n",
      "b tensor([0.2409])\n",
      "epoch 63, loss 52.928829\n",
      "w tensor([[-0.0757,  0.0776, -0.2446,  1.1118,  0.1433,  0.3663,  0.0573, -0.0792,\n",
      "         -0.4319,  0.0248,  0.3811,  0.0321, -0.4753]])\n",
      "b tensor([0.2464])\n",
      "epoch 64, loss 52.514603\n",
      "w tensor([[-0.0747,  0.0788, -0.2441,  1.1257,  0.1485,  0.3764,  0.0595, -0.0821,\n",
      "         -0.4271,  0.0244,  0.3826,  0.0318, -0.4831]])\n",
      "b tensor([0.2521])\n",
      "epoch 65, loss 52.285206\n",
      "w tensor([[-0.0728,  0.0789, -0.2436,  1.1420,  0.1532,  0.3858,  0.0612, -0.0848,\n",
      "         -0.4208,  0.0247,  0.3838,  0.0315, -0.4924]])\n",
      "b tensor([0.2574])\n",
      "epoch 66, loss 51.660614\n",
      "w tensor([[-0.0734,  0.0802, -0.2444,  1.1551,  0.1575,  0.3953,  0.0627, -0.0887,\n",
      "         -0.4170,  0.0230,  0.3837,  0.0312, -0.5034]])\n",
      "b tensor([0.2621])\n",
      "epoch 67, loss 52.541965\n",
      "w tensor([[-0.0731,  0.0805, -0.2448,  1.1687,  0.1615,  0.4044,  0.0629, -0.0919,\n",
      "         -0.4124,  0.0219,  0.3839,  0.0300, -0.5136]])\n",
      "b tensor([0.2665])\n",
      "epoch 68, loss 51.251640\n",
      "w tensor([[-0.0728,  0.0805, -0.2425,  1.1833,  0.1687,  0.4164,  0.0675, -0.0936,\n",
      "         -0.4069,  0.0232,  0.3870,  0.0321, -0.5206]])\n",
      "b tensor([0.2742])\n",
      "epoch 69, loss 50.717464\n",
      "w tensor([[-0.0710,  0.0794, -0.2426,  1.1956,  0.1725,  0.4252,  0.0674, -0.0972,\n",
      "         -0.4012,  0.0225,  0.3873,  0.0303, -0.5301]])\n",
      "b tensor([0.2786])\n",
      "epoch 70, loss 51.129803\n",
      "w tensor([[-0.0689,  0.0824, -0.2406,  1.2119,  0.1793,  0.4367,  0.0707, -0.0990,\n",
      "         -0.3957,  0.0234,  0.3898,  0.0318, -0.5372]])\n",
      "b tensor([0.2858])\n",
      "epoch 71, loss 49.960297\n",
      "w tensor([[-0.0701,  0.0835, -0.2417,  1.2242,  0.1833,  0.4466,  0.0716, -0.1014,\n",
      "         -0.3915,  0.0222,  0.3905,  0.0311, -0.5468]])\n",
      "b tensor([0.2909])\n",
      "epoch 72, loss 53.518608\n",
      "w tensor([[-0.0699,  0.0807, -0.2429,  1.2382,  0.1860,  0.4545,  0.0713, -0.1077,\n",
      "         -0.3885,  0.0195,  0.3888,  0.0286, -0.5571]])\n",
      "b tensor([0.2939])\n",
      "epoch 73, loss 49.407860\n",
      "w tensor([[-0.0686,  0.0834, -0.2409,  1.2519,  0.1930,  0.4662,  0.0737, -0.1074,\n",
      "         -0.3822,  0.0211,  0.3919,  0.0305, -0.5643]])\n",
      "b tensor([0.3015])\n",
      "epoch 74, loss 49.374683\n",
      "w tensor([[-0.0669,  0.0856, -0.2386,  1.2677,  0.1990,  0.4768,  0.0756, -0.1096,\n",
      "         -0.3756,  0.0224,  0.3936,  0.0305, -0.5706]])\n",
      "b tensor([0.3080])\n",
      "epoch 75, loss 48.984627\n",
      "w tensor([[-0.0683,  0.0843, -0.2385,  1.2803,  0.2042,  0.4871,  0.0775, -0.1128,\n",
      "         -0.3713,  0.0218,  0.3950,  0.0307, -0.5791]])\n",
      "b tensor([0.3138])\n",
      "epoch 76, loss 48.463566\n",
      "w tensor([[-0.0675,  0.0856, -0.2386,  1.2940,  0.2090,  0.4973,  0.0780, -0.1154,\n",
      "         -0.3670,  0.0207,  0.3960,  0.0304, -0.5874]])\n",
      "b tensor([0.3198])\n",
      "epoch 77, loss 48.204014\n",
      "w tensor([[-0.0663,  0.0857, -0.2377,  1.3081,  0.2145,  0.5075,  0.0793, -0.1178,\n",
      "         -0.3618,  0.0205,  0.3972,  0.0300, -0.5939]])\n",
      "b tensor([0.3255])\n",
      "epoch 78, loss 48.309902\n",
      "w tensor([[-0.0649,  0.0849, -0.2353,  1.3236,  0.2207,  0.5183,  0.0819, -0.1215,\n",
      "         -0.3557,  0.0209,  0.3988,  0.0307, -0.6012]])\n",
      "b tensor([0.3320])\n",
      "epoch 79, loss 48.659897\n",
      "w tensor([[-0.0654,  0.0854, -0.2347,  1.3360,  0.2263,  0.5293,  0.0833, -0.1230,\n",
      "         -0.3502,  0.0210,  0.4008,  0.0311, -0.6065]])\n",
      "b tensor([0.3387])\n",
      "epoch 80, loss 48.801666\n",
      "w tensor([[-0.0626,  0.0854, -0.2365,  1.3487,  0.2291,  0.5372,  0.0823, -0.1291,\n",
      "         -0.3460,  0.0187,  0.3989,  0.0282, -0.6167]])\n",
      "b tensor([0.3418])\n",
      "epoch 81, loss 50.954716\n",
      "w tensor([[-0.0643,  0.0842, -0.2352,  1.3621,  0.2337,  0.5469,  0.0830, -0.1314,\n",
      "         -0.3421,  0.0176,  0.4001,  0.0271, -0.6245]])\n",
      "b tensor([0.3472])\n",
      "epoch 82, loss 46.997185\n",
      "w tensor([[-0.0654,  0.0878, -0.2338,  1.3741,  0.2415,  0.5602,  0.0853, -0.1306,\n",
      "         -0.3371,  0.0184,  0.4039,  0.0305, -0.6291]])\n",
      "b tensor([0.3562])\n",
      "epoch 83, loss 49.243679\n",
      "w tensor([[-0.0632,  0.0882, -0.2337,  1.3887,  0.2447,  0.5683,  0.0846, -0.1354,\n",
      "         -0.3322,  0.0171,  0.4031,  0.0279, -0.6375]])\n",
      "b tensor([0.3601])\n",
      "epoch 84, loss 46.744514\n",
      "w tensor([[-0.0628,  0.0882, -0.2311,  1.4021,  0.2513,  0.5795,  0.0862, -0.1376,\n",
      "         -0.3263,  0.0182,  0.4056,  0.0289, -0.6419]])\n",
      "b tensor([0.3673])\n",
      "epoch 85, loss 46.366100\n",
      "w tensor([[-0.0615,  0.0874, -0.2300,  1.4146,  0.2572,  0.5901,  0.0881, -0.1401,\n",
      "         -0.3205,  0.0185,  0.4075,  0.0285, -0.6467]])\n",
      "b tensor([0.3739])\n",
      "epoch 86, loss 46.425724\n",
      "w tensor([[-0.0610,  0.0903, -0.2300,  1.4283,  0.2625,  0.6010,  0.0876, -0.1419,\n",
      "         -0.3155,  0.0176,  0.4079,  0.0285, -0.6538]])\n",
      "b tensor([0.3799])\n",
      "epoch 87, loss 46.662502\n",
      "w tensor([[-0.0602,  0.0897, -0.2265,  1.4451,  0.2696,  0.6129,  0.0899, -0.1448,\n",
      "         -0.3086,  0.0193,  0.4109,  0.0298, -0.6593]])\n",
      "b tensor([0.3876])\n",
      "epoch 88, loss 45.635372\n",
      "w tensor([[-0.0592,  0.0897, -0.2265,  1.4566,  0.2744,  0.6229,  0.0904, -0.1481,\n",
      "         -0.3041,  0.0179,  0.4115,  0.0286, -0.6647]])\n",
      "b tensor([0.3932])\n",
      "epoch 89, loss 45.518383\n",
      "w tensor([[-0.0606,  0.0893, -0.2245,  1.4722,  0.2805,  0.6337,  0.0918, -0.1504,\n",
      "         -0.2994,  0.0180,  0.4131,  0.0289, -0.6704]])\n",
      "b tensor([0.3998])\n",
      "epoch 90, loss 46.434036\n",
      "w tensor([[-0.0595,  0.0887, -0.2235,  1.4843,  0.2838,  0.6419,  0.0908, -0.1543,\n",
      "         -0.2958,  0.0167,  0.4129,  0.0267, -0.6765]])\n",
      "b tensor([0.4042])\n",
      "epoch 91, loss 46.256527\n",
      "w tensor([[-0.0603,  0.0879, -0.2228,  1.4977,  0.2895,  0.6535,  0.0920, -0.1576,\n",
      "         -0.2910,  0.0160,  0.4143,  0.0272, -0.6827]])\n",
      "b tensor([0.4109])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92, loss 44.945644\n",
      "w tensor([[-0.0594,  0.0892, -0.2205,  1.5106,  0.2969,  0.6658,  0.0939, -0.1584,\n",
      "         -0.2857,  0.0167,  0.4170,  0.0293, -0.6869]])\n",
      "b tensor([0.4190])\n",
      "epoch 93, loss 45.056442\n",
      "w tensor([[-0.0610,  0.0906, -0.2198,  1.5240,  0.3018,  0.6760,  0.0934, -0.1609,\n",
      "         -0.2818,  0.0157,  0.4176,  0.0279, -0.6915]])\n",
      "b tensor([0.4250])\n",
      "epoch 94, loss 44.553871\n",
      "w tensor([[-0.0591,  0.0908, -0.2180,  1.5377,  0.3083,  0.6873,  0.0952, -0.1625,\n",
      "         -0.2764,  0.0161,  0.4198,  0.0289, -0.6960]])\n",
      "b tensor([0.4323])\n",
      "epoch 95, loss 44.358845\n",
      "w tensor([[-0.0588,  0.0889, -0.2164,  1.5500,  0.3133,  0.6974,  0.0944, -0.1667,\n",
      "         -0.2705,  0.0161,  0.4207,  0.0279, -0.7011]])\n",
      "b tensor([0.4382])\n",
      "epoch 96, loss 44.617706\n",
      "w tensor([[-0.0590,  0.0918, -0.2145,  1.5635,  0.3202,  0.7093,  0.0958, -0.1667,\n",
      "         -0.2667,  0.0162,  0.4230,  0.0293, -0.7038]])\n",
      "b tensor([0.4461])\n",
      "epoch 97, loss 44.586361\n",
      "w tensor([[-0.0584,  0.0912, -0.2128,  1.5730,  0.3258,  0.7195,  0.0960, -0.1696,\n",
      "         -0.2611,  0.0165,  0.4244,  0.0288, -0.7070]])\n",
      "b tensor([0.4526])\n",
      "epoch 98, loss 44.526558\n",
      "w tensor([[-0.0584,  0.0904, -0.2104,  1.5888,  0.3318,  0.7309,  0.0973, -0.1726,\n",
      "         -0.2570,  0.0157,  0.4261,  0.0293, -0.7116]])\n",
      "b tensor([0.4593])\n",
      "epoch 99, loss 44.222729\n",
      "w tensor([[-0.0583,  0.0901, -0.2109,  1.6027,  0.3354,  0.7395,  0.0963, -0.1768,\n",
      "         -0.2530,  0.0138,  0.4250,  0.0275, -0.7180]])\n",
      "b tensor([0.4638])\n",
      "epoch 100, loss 44.980465\n",
      "w tensor([[-0.0560,  0.0901, -0.2108,  1.6145,  0.3409,  0.7500,  0.0960, -0.1788,\n",
      "         -0.2496,  0.0129,  0.4266,  0.0270, -0.7210]])\n",
      "b tensor([0.4705])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter:\n",
    "        trainer.zero_grad()\n",
    "        l = loss(model.forward(X).reshape(-1), y)\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l = loss(model.forward(data).reshape(-1), target)\n",
    "    print('epoch %d, loss %f' % (epoch, l.item()))\n",
    "    print('w',model[0].weight.data)\n",
    "    print('b',model[0].bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0093a6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0560,  0.0901, -0.2108,  1.6145,  0.3409,  0.7500,  0.0960, -0.1788,\n",
       "         -0.2496,  0.0129,  0.4266,  0.0270, -0.7210]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09f74a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4705])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98e54df",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ad7f2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0560,  0.0901, -0.2108,  1.6145,  0.3409,  0.7500,  0.0960, -0.1788,\n",
       "         -0.2496,  0.0129,  0.4266,  0.0270, -0.7210]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcc99fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred 19, y_true 19.100000381469727, pred-true diff 0.094286\n",
      "y_pred 19, y_true 20.600000381469727, pred-true diff -1.573545\n",
      "y_pred 21, y_true 15.199999809265137, pred-true diff 6.707854\n",
      "y_pred 16, y_true 7.0, pred-true diff 9.785456\n",
      "y_pred 11, y_true 8.100000381469727, pred-true diff 3.593592\n",
      "y_pred 22, y_true 13.600000381469727, pred-true diff 9.142576\n",
      "y_pred 24, y_true 20.100000381469727, pred-true diff 4.716501\n",
      "y_pred 21, y_true 21.799999237060547, pred-true diff -0.331268\n",
      "y_pred 19, y_true 24.5, pred-true diff -5.106640\n",
      "y_pred 14, y_true 23.100000381469727, pred-true diff -8.281129\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,X_val.shape[0]):\n",
    "    y_pred = model(X_val[i]).reshape(-1)\n",
    "    l = y_pred - y_val[i]   \n",
    "    print('y_pred %d, y_true %s, pred-true diff %f' % (y_pred.item(), y_val[i].item(), l.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bc35d2",
   "metadata": {},
   "source": [
    "2. Реализовать наивный баесовский классификатор для MNIST (взяв всего 2 цифры “1” и “2”) сравнить с sclearn’овским"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2adecd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "785328fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "#Select only the digit 4 and 9 images\n",
    "X = X[np.logical_or(y == 1, y == 2)]\n",
    "y = y[np.logical_or(y == 1, y == 2)]\n",
    "\n",
    "# verify selection\n",
    "np.unique(y)\n",
    "#array([1, 2])\n",
    "\n",
    "# Now split them\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=200, test_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7456886d",
   "metadata": {},
   "source": [
    "#### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8de6e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Multinomial Naive Bayes Classifier\n",
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fe0d4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 94.0 %\n",
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.91      0.93        43\n",
      "           2       0.93      0.96      0.95        57\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.94      0.94      0.94       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_predicted = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the prediction\n",
    "print(\"Accuracy = {} %\".format(accuracy_score(y_test, y_predicted)*100))\n",
    "\n",
    "# Cross validate the scores\n",
    "print(\"Classification Report \\n {}\".format(classification_report(y_test, y_predicted, labels=range(1,3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec1051",
   "metadata": {},
   "source": [
    "### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b516c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe01f712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to .\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f3c67008204d5db2003a17c1366aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\train-images-idx3-ubyte.gz to .\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to .\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff51b269e444a198865fd4d95f3a01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\train-labels-idx1-ubyte.gz to .\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to .\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9325a4e35d40889f0ecfae8f04aa2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to .\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to .\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243baf65eae8444b9b80f74148cbf4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to .\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_train = torchvision.datasets.MNIST('.', train=True, transform=data_transform, download=True)\n",
    "mnist_test  = torchvision.datasets.MNIST('.', train=False, transform=data_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a47fdd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 28, 28]), torch.Size([10]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = torch.stack([mnist_train[i][0] for i in range(2,38) if mnist_train[i][1] == 1 or mnist_train[i][1] == 2], \n",
    "                     dim=1).squeeze(0)\n",
    "labels = torch.tensor([mnist_train[i][1] for i in range(2,38) if mnist_train[i][1] == 1 or mnist_train[i][1] == 2])\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dad175a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.stack([mnist_train[i][0] for i in range(len(mnist_train)) if mnist_train[i][1] == 1 or mnist_train[i][1] == 2], \n",
    "                dim=1).squeeze(0)\n",
    "Y = torch.tensor([mnist_train[i][1] for i in range(len(mnist_train)) if mnist_train[i][1] == 1 or mnist_train[i][1] == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17449bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.5309, 0.4691])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_y = torch.zeros(3)\n",
    "for y in range(3):\n",
    "    n_y[y] = (Y == y).sum()\n",
    "P_y = n_y / n_y.sum()\n",
    "P_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02a3d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = torch.zeros((3, 28, 28))\n",
    "for y in range(3):\n",
    "    n_x[y] = torch.tensor(X.numpy()[Y.numpy() == y].sum(axis=0))\n",
    "P_xy = (n_x + 1) / (n_y + 1).reshape(3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fd2f65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bayes_pred(x):\n",
    "    x = x.unsqueeze(0)  # (28, 28) -> (1, 28, 28)\n",
    "    p_xy = P_xy * x + (1 - P_xy)*(1 - x)\n",
    "    p_xy = p_xy.reshape(3, -1).prod(dim=1)  # p(x|y)\n",
    "    return p_xy * P_y\n",
    "\n",
    "image, label = mnist_test[0]\n",
    "bayes_pred(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8cb8f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "underflow: 0.0\n",
      "logarithm is normal: -1805.2267129073316\n"
     ]
    }
   ],
   "source": [
    "a = 0.1\n",
    "print('underflow:', a**784)\n",
    "print('logarithm is normal:', 784*math.log(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef08d238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([      nan, -300.4918, -252.6362])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_P_xy = torch.log(P_xy)\n",
    "log_P_xy_neg = torch.log(1 - P_xy)\n",
    "log_P_y = torch.log(P_y)\n",
    "\n",
    "def bayes_pred_stable(x):\n",
    "    x = x.unsqueeze(0)  # (28, 28) -> (1, 28, 28)\n",
    "    p_xy = log_P_xy * x + log_P_xy_neg * (1 - x)\n",
    "    p_xy = p_xy.reshape(3, -1).sum(axis=1)  # p(x|y)\n",
    "    return p_xy + log_P_y\n",
    "\n",
    "py = bayes_pred_stable(image)\n",
    "py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e548618b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.argmax(dim=0) == label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a4c5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    return [bayes_pred_stable(x).argmax(dim=0).type(torch.int32).item() \n",
    "            for x in X]\n",
    "\n",
    "X = torch.stack([mnist_train[i][0] for i in range(3,38) if mnist_train[i][1] == 1 or mnist_train[i][1] == 2], dim=1).squeeze(0)\n",
    "y = torch.tensor([mnist_train[i][1] for i in range(3,38) if mnist_train[i][1] == 1 or mnist_train[i][1] == 2])\n",
    "preds = predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee59b827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09584513692162418"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.stack([mnist_train[i][0] for i in range(len(mnist_test)) if mnist_train[i][1] == 1 or mnist_train[i][1] == 2], \n",
    "                dim=1).squeeze(0)\n",
    "y = torch.tensor([mnist_train[i][1] for i in range(len(mnist_test)) if mnist_train[i][1] == 1 or mnist_train[i][1] == 2])\n",
    "preds = torch.tensor(predict(X), dtype=torch.int32)\n",
    "float((preds == y).sum()) / len(y)  # Validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16771dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
